{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ensemble Learning",
   "id": "575c4cb5c554f2f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Imports and Setting up the Kaggle API\n",
    "### Create .env File and Set KAGGLE_KEY and KAGGLE_USERNAME as Kaggle Username and Key in .env File\n",
    "### Example:\n",
    "KAGGLE_KEY=API_KEY\n",
    "KAGGLE_USERNAME=USERNAME\n",
    "\n",
    "load_dotenv will take .env and set key pairs as environmental variables in Python"
   ],
   "id": "297190960c102f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T01:09:14.981612Z",
     "start_time": "2025-11-28T01:09:14.962668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import kaggle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ],
   "id": "856954414c93e72",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Setting the API Instance and downloading dataset",
   "id": "6b090646430f7745"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T01:09:15.510232Z",
     "start_time": "2025-11-28T01:09:15.009262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "apiInstance=kaggle.KaggleApi()\n",
    "apiInstance.dataset_download_files('fedesoriano/stroke-prediction-dataset', unzip=True)"
   ],
   "id": "471110ed8d675f2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset\n"
     ]
    }
   ],
   "execution_count": 201
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing\n",
   "id": "11c341ab6eddc815"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T01:09:15.529050Z",
     "start_time": "2025-11-28T01:09:15.514174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "strokeData=pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "#strokeData.info()\n",
    "strokeDataFeatures=strokeData.iloc[:,1:-1]\n",
    "#iloc[rows,columns] we used : on rows as :specifies a range so a range with no upper or lower bound means taking everyting\n",
    "#1:-1 means a range from 1(dropping our first column) to -1(which really means our last column)\n",
    "#dropping the first column our ID column since it has no predictive power and can potentially cause any learners we use to develop patterns on it\n",
    "#dropping the last column since we only want our features and not the labels\n",
    "strokeDataLabels=strokeData.iloc[:,-1]\n",
    "#getting only the last column as we only want the labels"
   ],
   "id": "5b0679b68ba4edbb",
   "outputs": [],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T01:09:15.547733Z",
     "start_time": "2025-11-28T01:09:15.534889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(strokeData.isnull().any())\n",
    "#BMI is the only column with NaNs\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer(strategy='mean')\n",
    "# our BMI column is our 8th column so we want to put that column in the imputer\n",
    "strokeDataFeatures[['bmi']]=pd.DataFrame(imputer.fit_transform(strokeDataFeatures[['bmi']]))\n",
    "print(strokeDataFeatures.isnull().any())"
   ],
   "id": "c0b9f15663beb258",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                   False\n",
      "gender               False\n",
      "age                  False\n",
      "hypertension         False\n",
      "heart_disease        False\n",
      "ever_married         False\n",
      "work_type            False\n",
      "Residence_type       False\n",
      "avg_glucose_level    False\n",
      "bmi                   True\n",
      "smoking_status       False\n",
      "stroke               False\n",
      "dtype: bool\n",
      "gender               False\n",
      "age                  False\n",
      "hypertension         False\n",
      "heart_disease        False\n",
      "ever_married         False\n",
      "work_type            False\n",
      "Residence_type       False\n",
      "avg_glucose_level    False\n",
      "bmi                  False\n",
      "smoking_status       False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T01:09:15.579982Z",
     "start_time": "2025-11-28T01:09:15.553114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#we want to use standard scaler to scale the inputs for the numberical inputs to avoid problems with weights for different model types\n",
    "#standard scaler or minmax scaler are good but we will use StandardScaler\n",
    "#we want to use onehotencoder for categorical columns\n",
    "# that have more than 2 possible awnsers, ordinal or label encoder for categorical columsn that have only 2 possible awnsers and then we want to use the columnTransformer to apply these encoders to the columsn we want to apply them to\n",
    "\n",
    "#these lines help us figure out which columsn need to be onehotencoded and which need to be converted to binary\n",
    "print('Columns to be OneHotEncoded')\n",
    "for column in strokeDataFeatures:\n",
    "    if (strokeDataFeatures[column].nunique()>2) & (strokeDataFeatures[column].dtype == 'object'):\n",
    "        print(f'{column} has unique categories of {strokeDataFeatures[column].unique()}')\n",
    "#gender work_type and smoking_status should be OneHotEncoded to avoid the learners accidentally ranking\n",
    "print('Columns to be converted to Binary')\n",
    "for column in strokeDataFeatures:\n",
    "    if (strokeDataFeatures[column].nunique()==2) & (strokeDataFeatures[column].dtype == 'object'):\n",
    "        print(f'{column} has unique categories of {strokeDataFeatures[column].unique()}')\n",
    "#ever_married and residence_type can be converted to binary 0 and 1 since there are only 2 values\n",
    "\n",
    "#column transformer takes in an array of tuples(each tuples has three values) each tuple is represents an encoder you will use on some columns in the tuples you have three values the first value is some arbitrary name like 'ordinalEncoder' and the second vlaue is the function for the encoder itself like OrdinalEncoder() the third value is a list of the column indices or column names if the data is a dataframe which you want that specific encoder to be used on so in this case we only want our OrdinalEncoder to\n",
    "ct=ColumnTransformer(transformers=[('ordinalEncoder', OrdinalEncoder(), ['ever_married','Residence_type']),('oneHotEncoder', OneHotEncoder(), ['gender','work_type','smoking_status']),('scaler', StandardScaler(),['bmi','avg_glucose_level','age'])],remainder='passthrough')\n",
    "strokeDataFeatures=ct.fit_transform(strokeDataFeatures)\n",
    "print(ct.get_feature_names_out())\n",
    "strokeDataFeatures[0]\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "2120871b07da2b7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to be OneHotEncoded\n",
      "gender has unique categories of ['Male' 'Female' 'Other']\n",
      "work_type has unique categories of ['Private' 'Self-employed' 'Govt_job' 'children' 'Never_worked']\n",
      "smoking_status has unique categories of ['formerly smoked' 'never smoked' 'smokes' 'Unknown']\n",
      "Columns to be converted to Binary\n",
      "ever_married has unique categories of ['Yes' 'No']\n",
      "Residence_type has unique categories of ['Urban' 'Rural']\n",
      "['ordinalEncoder__ever_married' 'ordinalEncoder__Residence_type'\n",
      " 'oneHotEncoder__gender_Female' 'oneHotEncoder__gender_Male'\n",
      " 'oneHotEncoder__gender_Other' 'oneHotEncoder__work_type_Govt_job'\n",
      " 'oneHotEncoder__work_type_Never_worked'\n",
      " 'oneHotEncoder__work_type_Private'\n",
      " 'oneHotEncoder__work_type_Self-employed'\n",
      " 'oneHotEncoder__work_type_children'\n",
      " 'oneHotEncoder__smoking_status_Unknown'\n",
      " 'oneHotEncoder__smoking_status_formerly smoked'\n",
      " 'oneHotEncoder__smoking_status_never smoked'\n",
      " 'oneHotEncoder__smoking_status_smokes' 'scaler__bmi'\n",
      " 'scaler__avg_glucose_level' 'scaler__age' 'remainder__hypertension'\n",
      " 'remainder__heart_disease']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 1.00123401,\n",
       "       2.70637544, 1.05143428, 0.        , 1.        ])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T01:09:15.585926Z",
     "start_time": "2025-11-28T01:09:15.584245Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "73f707fc667d8f38",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
